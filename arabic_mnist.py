# -*- coding: utf-8 -*-
"""arabic_mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vOpl8_4QTydizKOAV_vyG-KeuW38TEA0

# Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# Python packages to manipulate files
import os
import pathlib
from pathlib import Path
import datetime

# Tensorflow and Numpy packages
import tensorflow as tf
import numpy as np

# Display related packages
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from IPython.display import Image
import PIL
import PIL.Image

# %matplotlib inline

"""# Check available compute capabilities
If you have a GPU uncomment the last line to check that your Tensorflow installation supports GPU
This is a colab notebook, so no need for these commands, unless you're running it on your local machine
"""

#my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')
#tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')
#tf.config.set_visible_devices([], 'GPU')

"""# The image dataset

"""

# Use this code to uncompress the image dataset.
!tar xvzf '/content/arabic_handwritten_data.tgz' -C '/content/arabic_handwritten_data'

# We open a random file from the dataset and display it.
Image(filename = "/content/arabic_handwritten_data/data/test_data/id_10_label_5.png", width = 32, height = 32)

# We list the files inside each folder and we can see that we have thousands of png files that have a similar naming pattern. We can guess the letter to which the image belongs through the file name. We pick a random set of files and display their names.
directory = "/content/arabic_handwritten_data/data/train_data/"
images = os.listdir(directory)
images[0:12]

"""# Displaying the data
We pick 12 images and display them in a grid using matplotlib.
"""

ncols = 4
nrows = 4

fig = plt.gcf()
fig.set_size_inches(ncols*2, nrows*2)

for i, img_path in enumerate(images[0:ncols*nrows]):
    sp = plt.subplot(nrows, ncols, i + 1)
    sp.axis('Off') # Disable axes display

    img = mpimg.imread( directory + img_path ) 
    plt.imshow(img)

plt.show()

"""# Define the data dictionary
To identify the model predictions easilly, we create a list identifing each label. The list contains the real name of the letter instead of just its index in the alphabet order. We provide two versions of this list:

the first one shows letters written in latin with phonetic representation.
the second one shows the letters in arabic.
"""

arabic_characters = ['alef', 'beh', 'teh', 'theh', 'jeem', 'hah', 'khah', 'dal', 'thal',
                    'reh', 'zain', 'seen', 'sheen', 'sad', 'dad', 'tah', 'zah', 'ain',
                    'ghain', 'feh', 'qaf', 'kaf', 'lam', 'meem', 'noon', 'heh', 'waw', 'yeh']
print(len(arabic_characters))
print(arabic_characters[12])

arabic_char_utf8 = ("أ","ب","ت","ث","ج","ح","خ","د","ذ","ر","ز","س","ش","ص","ض","ط","ظ","ع","غ","ف","ق","ك","ل","م","ن","ه","و","ي")

print(arabic_char_utf8[12])

"""# Tensorboard and Monitoring

We create a folder to store tensorflow logs and display them in Tensorboard.

Tensorboard is a tool that allows you to track model metrics.

Jupyter and Google colab allows you to display Tensorboard inside the notebook through an extension.
"""

# Commented out IPython magic to ensure Python compatibility.
logdir = os.path.join("/content/logs/gradient_tape/20201123-122547/", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
# %load_ext tensorboard
# %tensorboard --logdir $logdir

"""# Load the data
We process the folder and load each files in it.

We extract the label of each picture and convert the image to a rescaled matrix of 32x32x3.
"""

batch_size = 32
img_height = 32
img_width = 32

def get_dataset(dataset_dir):
    
    def process_filename(file_path):
        # Replace elements of input matching regex pattern with rewrite.
        label = tf.strings.regex_replace( input = file_path, pattern = r".+_label_(\d+)\.png", rewrite = r"\1" )
        label = tf.strings.to_number(label, tf.int32)-1
        #label = tf.one_hot(label, depth=29)
        return label

    def process_img(file_path):
        img = tf.io.read_file(file_path)
        img = tf.image.decode_png(img, channels=3) #  0: Use the number of channels in the PNG-encoded image. 1: output a grayscale image. 3: output an RGB image. 4: output an RGBA image.
        img = tf.image.resize(img, size=(32, 32))
        img = tf.image.convert_image_dtype(img, tf.float32)
        img = tf.cast(img, tf.float32) / 255.0
        # The reason for normalizing the images is to avoid the possibility of exploding gradients because of the high range of the pixels [0, 255], and improve the convergence speed. 
        # Therefore, you either standardize each image, so that the range is [-1, 1] or you just divide by the maximum pixel value (255), so that the range of the pixels is in the [0, 1] range.
        # Another reason why you might want to normalize the image data is if you are using transfer learning. 
        # For example, if you are using a pre-trained model that has been trained with images with pixels in the [0, 1] range, you should make sure that the inputs you are providing the model are in the same range. 
        return img
    
    data_dir = pathlib.Path(dataset_dir)
    file_list = [ str( path.absolute() ) for path in Path(data_dir).glob("*.png") ] # find all the files in a directory having the extension .png using the for loop, then we'll have the absolute path in a string format
    # The simplest way to create a dataset is to create it from a python list
    files_ds = tf.data.Dataset.from_tensor_slices((file_list))
    # The map() method creates a new array populated with the results of calling a provided function on every element in the calling array.
    # A lambda function is a small anonymous function. A lambda function can take any number of arguments, but can only have one expression.
    files_ds = files_ds.map(lambda x: (process_img(x), process_filename(x))) # Couple the image processing with the names
    return files_ds

train_dataset_path = "/content/arabic_handwritten_data/data/train_data/"
test_dataset_path = "/content/arabic_handwritten_data/data/test_data/"

train_ds = get_dataset(train_dataset_path).shuffle(buffer_size=batch_size*10).batch(batch_size)
valid_ds = get_dataset(test_dataset_path).batch(batch_size)

"""# Define the neural network structure"""

model = tf.keras.Sequential([
    # Convert the 32x32x3 image into a flat vector of 32x32x3 = 3072 values
    tf.keras.layers.Flatten(input_shape=(32, 32, 3), name='flatten_input'),
    # Create a "hidden" layer with 256 neurons and apply the ReLU non-linearity
    tf.keras.layers.Dense(256, activation=tf.nn.relu, name='input_to_hidden1'),
    # Create another hidden layer with 128 neurons
    tf.keras.layers.Dense(128, activation=tf.nn.relu, name='hidden1_to_hidden2'),
    # Create an "output layer" with 28 neurons
    tf.keras.layers.Dense(28, name='hidden_to_logits'),
])
model.summary()

"""# Define the optimizer and the loss

In this example, we use SparseCategoricalCrossentropy because the label is defined as a number.

If we use a one hot vector instead, we should use CategoricalCrossentropy.
"""

optimizer = tf.keras.optimizers.Adam(lr=1E-3)
# Consider a classification problem with 5 categories (or classes).
# In the case of cce, the one-hot target may be [0, 1, 0, 0, 0] and the model may predict [.2, .5, .1, .1, .1] (probably right)
# In the case of scce, the target index may be [1] and the model may predict: [.5].
# In short, use sparse_categorical_crossentropy when your classes are mutually exclusive, i.e. you don't care at all about other close enough predictions.
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')

valid_loss = tf.keras.metrics.Mean(name='valid_loss')
valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')

"""# Prepare the training loop

We define a train_step function that would update the newtork weights each time it is called.

We also define a similar function to track the performance of the model on the validation set.
"""

num_epochs = 50  # The number of epochs to run

# Lists to store the loss and accuracy of every epoch
train_losses = []
train_accuracies = []
valid_losses = []
valid_accuracies = []

# Defined a function to train the model using tf.GradientTape
@tf.function
def train_step(image, label):
  # Initialise a GradientTape to track the operations
  # https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb
  with tf.GradientTape() as tape:
    # Compute the logits (un-normalised scores) of the current batch of examples
    # using the neural network architecture we defined earlier
    logits = model(image) # Logits are values that are used as input to softmax. 
    loss = loss_object(label, logits)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))
  
  # Add current batch loss to our loss metric tracker - note the function call semantics
  train_loss(loss)
  train_accuracy(label, logits)

@tf.function
def valid_step(image, label):
    valid_logits = model(image, training=False)
    valid_accuracy(label, valid_logits)
    loss = loss_object(label, valid_logits)
    valid_loss(loss)

"""
# Create folders to collect statistics for Tensorboard"""

current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
train_log_dir = 'logs/gradient_tape/' + current_time + '/train'
valid_log_dir = 'logs/gradient_tape/' + current_time + '/valid'
train_summary_writer = tf.summary.create_file_writer(train_log_dir)
valid_summary_writer = tf.summary.create_file_writer(valid_log_dir)

"""# Run the training loop



"""

for epoch in range(num_epochs):
  # Loop over our data pipeline
  for image, label in train_ds:
    train_step(image, label)

  for image, label in valid_ds:
    valid_step(image, label)

  # Code specific to Tensorflow 
  with train_summary_writer.as_default():
    tf.summary.scalar('loss', train_loss.result(), step=epoch)
    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)

  with valid_summary_writer.as_default():
    tf.summary.scalar('loss', valid_loss.result(), step=epoch)
    tf.summary.scalar('accuracy', valid_accuracy.result(), step=epoch)

  template = 'Epoch {:03d}, Train Loss: {:.3f}, Train Accuracy: {:.3%}, Valid Loss: {:.3f}, Valid Accuracy: {:.3%}'
  print(template.format(epoch+1,
                        train_loss.result(), 
                        train_accuracy.result(),
                        valid_loss.result(),
                        valid_accuracy.result(),
                       ))
  
  train_losses.append(train_loss.result())
  train_accuracies.append(train_accuracy.result())
  valid_losses.append(valid_loss.result())
  valid_accuracies.append(valid_accuracy.result())

"""# Plot the loss and the accuracy"""

# Plot the loss for all epochs using Matplotlib
plt.figure()
plt.plot(range(num_epochs), train_losses)
plt.plot(range(num_epochs), valid_losses)
plt.title('Loss vs epochs')

# Plot the accuracy for all epochs using Matplotlib
plt.figure()
plt.plot(range(num_epochs), train_accuracies)
plt.plot(range(num_epochs), valid_accuracies)
plt.title('Accuracy vs epochs')

"""# Display predictions


"""

images, labels = next(iter(valid_ds)) # iterate through the validation dataset to have the images and their labels
# Logit is a function that maps probabilities [0, 1] to [-inf, +inf].
# Softmax is a function that maps [-inf, +inf] to [0, 1] similar as Sigmoid. But Softmax also normalizes the sum of the values(output vector) to be 1.
# Tensorflow "with logit": It means that you are applying a softmax function to logit numbers to normalize it. The input_vector/logit is not normalized and can scale from [-inf, inf].

# raw_predictions = neural_net(input_layer) # => logit
# predicted_class_index_by_raw = argmax(raw_predictions)
# probabilities = softmax(raw_predictions)
# predicted_class_index_by_prob = argmax(probabilities)

_logits = model(images, training=False) # 32 values with is the batch size 
predicted_labels = tf.argmax(_logits, axis=1, output_type=tf.int32) # with argmax we have the number equivalent to the predicted letter ==> 32 value

# images.numpy().shape[3] #data shape 32*32*32*3
img_indexs = np.arange(images.numpy().shape[0]) # get images indexes
np.random.shuffle(img_indexs) #shuffle image indexes

plt.figure(figsize=(5,5))
for i in range(25):
    # prepare the grid for viz
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(True)

    # get the image index
    img_index = img_indexs[i]
    # show the image
    plt.imshow(images[img_index])

    # the predicted image label index
    predicted_label = int(predicted_labels[img_index])
    # the actual image label index
    actual_label = int(labels[img_index].numpy())
    
    # the result
    plt.xlabel("\n Actual: ({})\n Predicted: ({})".format(arabic_char_utf8[actual_label-1],  arabic_char_utf8[predicted_label-1]))

plt.tight_layout()
plt.show()

