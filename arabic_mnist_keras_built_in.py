# -*- coding: utf-8 -*-
"""arabic_mnist_keras_built_in.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vOpl8_4QTydizKOAV_vyG-KeuW38TEA0

# Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# Python packages to manipulate files
import os
import pathlib
from pathlib import Path
import datetime

# Tensorflow and Numpy packages
import tensorflow as tf
import numpy as np

# Display related packages
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from IPython.display import Image
import PIL
import PIL.Image

# %matplotlib inline

"""# Check available compute capabilities
If you have a GPU uncomment the last line to check that your Tensorflow installation supports GPU
This is a colab notebook, so no need for these commands, unless you're running it on your local machine
"""

#my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')
#tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')
#tf.config.set_visible_devices([], 'GPU')

"""# The image dataset

"""

# Use this code to uncompress the image dataset.
!tar xvzf '/content/arabic_handwritten_data.tgz' -C '/content/arabic_handwritten_data'

# We open a random file from the dataset and display it.
Image(filename = "/content/arabic_handwritten_data/data/test_data/id_10_label_5.png", width = 32, height = 32)

# We list the files inside each folder and we can see that we have thousands of png files that have a similar naming pattern. We can guess the letter to which the image belongs through the file name. We pick a random set of files and display their names.
directory = "/content/arabic_handwritten_data/data/train_data/"
images = os.listdir(directory)
images[0:12]

"""# Displaying the data
We pick 12 images and display them in a grid using matplotlib.
"""

ncols = 4
nrows = 4

fig = plt.gcf()
fig.set_size_inches(ncols*2, nrows*2)

for i, img_path in enumerate(images[0:ncols*nrows]):
    sp = plt.subplot(nrows, ncols, i + 1)
    sp.axis('Off') # Disable axes display

    img = mpimg.imread( directory + img_path ) 
    plt.imshow(img)

plt.show()

"""# Define the data dictionary
To identify the model predictions easilly, we create a list identifing each label. The list contains the real name of the letter instead of just its index in the alphabet order. We provide two versions of this list:

the first one shows letters written in latin with phonetic representation.
the second one shows the letters in arabic.
"""

arabic_characters = ['alef', 'beh', 'teh', 'theh', 'jeem', 'hah', 'khah', 'dal', 'thal',
                    'reh', 'zain', 'seen', 'sheen', 'sad', 'dad', 'tah', 'zah', 'ain',
                    'ghain', 'feh', 'qaf', 'kaf', 'lam', 'meem', 'noon', 'heh', 'waw', 'yeh']
print(len(arabic_characters))
print(arabic_characters[12])

arabic_char_utf8 = ("أ","ب","ت","ث","ج","ح","خ","د","ذ","ر","ز","س","ش","ص","ض","ط","ظ","ع","غ","ف","ق","ك","ل","م","ن","ه","و","ي")

print(arabic_char_utf8[12])

"""# Tensorboard and Monitoring

We create a folder to store tensorflow logs and display them in Tensorboard.

Tensorboard is a tool that allows you to track model metrics.

Jupyter and Google colab allows you to display Tensorboard inside the notebook through an extension.
"""

# Commented out IPython magic to ensure Python compatibility.
logdir = os.path.join("/content/logs/gradient_tape/20201123-122547/", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
# %load_ext tensorboard
# %tensorboard --logdir $logdir

"""# Load the data
We process the folder and load each files in it.

We extract the label of each picture and convert the image to a rescaled matrix of 32x32x3.
"""

batch_size = 32
img_height = 32
img_width = 32

def get_dataset(dataset_dir):
    
    def process_filename(file_path):
        # Replace elements of input matching regex pattern with rewrite.
        label = tf.strings.regex_replace( input = file_path, pattern = r".+_label_(\d+)\.png", rewrite = r"\1" )
        label = tf.strings.to_number(label, tf.int32)-1
        #label = tf.one_hot(label, depth=29)
        return label

    def process_img(file_path):
        img = tf.io.read_file(file_path)
        img = tf.image.decode_png(img, channels=3) #  0: Use the number of channels in the PNG-encoded image. 1: output a grayscale image. 3: output an RGB image. 4: output an RGBA image.
        img = tf.image.resize(img, size=(32, 32))
        img = tf.image.convert_image_dtype(img, tf.float32)
        img = tf.cast(img, tf.float32) / 255.0
        # The reason for normalizing the images is to avoid the possibility of exploding gradients because of the high range of the pixels [0, 255], and improve the convergence speed. 
        # Therefore, you either standardize each image, so that the range is [-1, 1] or you just divide by the maximum pixel value (255), so that the range of the pixels is in the [0, 1] range.
        # Another reason why you might want to normalize the image data is if you are using transfer learning. 
        # For example, if you are using a pre-trained model that has been trained with images with pixels in the [0, 1] range, you should make sure that the inputs you are providing the model are in the same range. 
        return img
    
    data_dir = pathlib.Path(dataset_dir)
    file_list = [ str( path.absolute() ) for path in Path(data_dir).glob("*.png") ] # find all the files in a directory having the extension .png using the for loop, then we'll have the absolute path in a string format
    # The simplest way to create a dataset is to create it from a python list
    files_ds = tf.data.Dataset.from_tensor_slices((file_list))
    # The map() method creates a new array populated with the results of calling a provided function on every element in the calling array.
    # A lambda function is a small anonymous function. A lambda function can take any number of arguments, but can only have one expression.
    files_ds = files_ds.map(lambda x: (process_img(x), process_filename(x))) # Couple the image processing with the names
    return files_ds

train_dataset_path = "/content/arabic_handwritten_data/data/train_data/"
test_dataset_path = "/content/arabic_handwritten_data/data/test_data/"

train_ds = get_dataset(train_dataset_path).shuffle(buffer_size=batch_size*10).batch(batch_size)
valid_ds = get_dataset(test_dataset_path).batch(batch_size)

"""# Define the neural network structure"""

model = tf.keras.Sequential([
    # Convert the 32x32x3 image into a flat vector of 32x32x3 = 3072 values
    tf.keras.layers.Flatten(input_shape=(32, 32, 3), name='flatten_input'),
    # Create a "hidden" layer with 256 neurons and apply the ReLU non-linearity
    tf.keras.layers.Dense(256, activation=tf.nn.relu, name='input_to_hidden1'),
    # Create another hidden layer with 128 neurons
    tf.keras.layers.Dense(128, activation=tf.nn.relu, name='hidden1_to_hidden2'),
    # Create an "output layer" with 28 neurons
    tf.keras.layers.Dense(28, name='hidden_to_logits'),
])
model.summary()

"""# Define the model optimizer and loss

In this example, we use SparseCategoricalCrossentropy because the label is defined as a number.

If we use a one hot vector instead, we should use CategoricalCrossentropy.
"""

# The difference between arabic_mnist and this notebook starts here .

model.compile(
    # Optimizer
    optimizer=tf.keras.optimizers.RMSprop(),  
    # Loss function to minimize
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    # List of metrics to monitor
    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],
)

"""# Define callbacks
Tensorflow provides a callback mechanism that allows us to execute different tasks during the training like collecting statistics for Tensorboard.
"""

# callbacks = [
#     tf.keras.callbacks.EarlyStopping(
#         # Stop training when `val_loss` is no longer improving
#         monitor="val_loss",
#         # "no longer improving" being defined as "no better than 1e-2 less"
#         min_delta=1e-2,
#         # "no longer improving" being further defined as "for at least 2 epochs"
#         patience=2,
#         verbose=1,
#     )
# ]
callbacks = [
    tf.keras.callbacks.TensorBoard(
        log_dir=logdir,
        histogram_freq=0,  # How often to log histogram visualizations
        embeddings_freq=0,  # How often to log embedding visualizations
        update_freq="epoch",
    ) 
]

"""# Launch the training.
You can see the progress of the training in the output below or in the Tensorboard widget loaded earlier.
"""

print("Fit model on training data")
history = model.fit(train_ds, epochs = 50, validation_data=valid_ds, callbacks = callbacks)

"""# Plot the loss and the accuracy"""

# Plot the loss for all epochs using Matplotlib
plt.figure()
plt.plot(range(num_epochs), train_losses)
plt.plot(range(num_epochs), valid_losses)
plt.title('Loss vs epochs')

# Plot the accuracy for all epochs using Matplotlib
plt.figure()
plt.plot(range(num_epochs), train_accuracies)
plt.plot(range(num_epochs), valid_accuracies)
plt.title('Accuracy vs epochs')

"""# Display predictions"""

images, labels = next(iter(valid_ds)) # iterate through the validation dataset to have the images and their labels
# Logit is a function that maps probabilities [0, 1] to [-inf, +inf].
# Softmax is a function that maps [-inf, +inf] to [0, 1] similar as Sigmoid. But Softmax also normalizes the sum of the values(output vector) to be 1.
# Tensorflow "with logit": It means that you are applying a softmax function to logit numbers to normalize it. The input_vector/logit is not normalized and can scale from [-inf, inf].

# raw_predictions = neural_net(input_layer) # => logit
# predicted_class_index_by_raw = argmax(raw_predictions)
# probabilities = softmax(raw_predictions)
# predicted_class_index_by_prob = argmax(probabilities)

_logits = model(images, training=False) # 32 values with is the batch size 
predicted_labels = tf.argmax(_logits, axis=1, output_type=tf.int32) # with argmax we have the number equivalent to the predicted letter ==> 32 value

# images.numpy().shape[3] #data shape 32*32*32*3
img_indexs = np.arange(images.numpy().shape[0]) # get images indexes
np.random.shuffle(img_indexs) #shuffle image indexes

plt.figure(figsize=(5,5))
for i in range(25):
    # prepare the grid for viz
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(True)

    # get the image index
    img_index = img_indexs[i]
    # show the image
    plt.imshow(images[img_index])

    # the predicted image label index
    predicted_label = int(predicted_labels[img_index])
    # the actual image label index
    actual_label = int(labels[img_index].numpy())
    
    # the result
    plt.xlabel("\n Actual: ({})\n Predicted: ({})".format(arabic_char_utf8[actual_label-1],  arabic_char_utf8[predicted_label-1]))

plt.tight_layout()
plt.show()

